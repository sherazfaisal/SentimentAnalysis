{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "424f51a3dc464260b9fb90ac7ef9d36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72c49273a945412ca7156b342524a8f5",
              "IPY_MODEL_517a273e57b9448fb647832cadd61c42",
              "IPY_MODEL_bff7d4b4887f4f5d8563e1659cf9f2a9"
            ],
            "layout": "IPY_MODEL_a078f84461824707adb84fb5a0185789"
          }
        },
        "72c49273a945412ca7156b342524a8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c6b30da2e794a0b8aec0052f54ceb7a",
            "placeholder": "​",
            "style": "IPY_MODEL_3bbaafc6f8d74347b5568cb2cf4bb8e0",
            "value": "100%"
          }
        },
        "517a273e57b9448fb647832cadd61c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7505c732aa402e9a4b79d28cd80799",
            "max": 200000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dc4d3a0202541a3bf067608fa668621",
            "value": 200000
          }
        },
        "bff7d4b4887f4f5d8563e1659cf9f2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e4ccc3980b440b93fcd74432485f78",
            "placeholder": "​",
            "style": "IPY_MODEL_837518e8ccb64f68856682512fd4da2f",
            "value": " 200000/200000 [03:28&lt;00:00, 1229.03it/s]"
          }
        },
        "a078f84461824707adb84fb5a0185789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c6b30da2e794a0b8aec0052f54ceb7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bbaafc6f8d74347b5568cb2cf4bb8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e7505c732aa402e9a4b79d28cd80799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc4d3a0202541a3bf067608fa668621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09e4ccc3980b440b93fcd74432485f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "837518e8ccb64f68856682512fd4da2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxDRVQa84tA-",
        "outputId": "e0c336c9-f19f-4aa9-a500-4db7510eb30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "# Load the pre-trained BERT model\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "import pandas as pd\n",
        "# Load the dataset from a CSV file\n",
        "df = pd.read_csv('labeled_twcs.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKBWVlYZ5Xe5",
        "outputId": "4d6c50a3-4296-45a8-dcd0-5449e3e56892"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-a6d364293691>:4: DtypeWarning: Columns (1,2,3,4,5,6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('labeled_twcs.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "# Separate positive and negative examples\n",
        "df_pos = df[df['label'] == 'POSITIVE']\n",
        "df_neg = df[df['label'] == 'NEGATIVE']\n",
        "\n",
        "# Downsample negative and positive examples to match each other\n",
        "df_neg_downsampled = resample(df_neg, replace=False, n_samples=100000, random_state=42)\n",
        "df_pos_downsampled = resample(df_pos, replace=False, n_samples=100000, random_state=42)\n",
        "\n",
        "# Combine the positive and negative examples\n",
        "df= pd.concat([df_pos_downsampled, df_neg_downsampled])"
      ],
      "metadata": {
        "id": "Z-IyorfP8G6b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "# Define the maximum sequence length\n",
        "max_len = 512\n",
        "df = df.fillna(\"\")\n",
        "\n",
        "# Tokenize the text and convert to input IDs and attention masks\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# Create a progress bar\n",
        "pbar = tqdm(total=len(df))\n",
        "\n",
        "for text in df['text']:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        truncation = True,\n",
        "                        max_length = max_len,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )        \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    # Update the progress bar for each batch\n",
        "    pbar.update()\n",
        "\n",
        "# Close the progress bar\n",
        "pbar.close()\n",
        "# Convert the lists to tensors\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "424f51a3dc464260b9fb90ac7ef9d36f",
            "72c49273a945412ca7156b342524a8f5",
            "517a273e57b9448fb647832cadd61c42",
            "bff7d4b4887f4f5d8563e1659cf9f2a9",
            "a078f84461824707adb84fb5a0185789",
            "3c6b30da2e794a0b8aec0052f54ceb7a",
            "3bbaafc6f8d74347b5568cb2cf4bb8e0",
            "2e7505c732aa402e9a4b79d28cd80799",
            "6dc4d3a0202541a3bf067608fa668621",
            "09e4ccc3980b440b93fcd74432485f78",
            "837518e8ccb64f68856682512fd4da2f"
          ]
        },
        "id": "Ob83bPIi43p3",
        "outputId": "f8d3e30a-18a2-4447-b759-1a7e75d2f8d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "424f51a3dc464260b9fb90ac7ef9d36f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "labels = torch.tensor(list(df['label_encoded']))\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=42, test_size=0.2)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=42, test_size=0.2)\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 4\n",
        "max_split_size_mb = 256\n",
        "\n",
        "# Training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size,\n",
        "                               pin_memory=True, num_workers=0)\n",
        "\n",
        "# Validation set\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size,\n",
        "                                    pin_memory=True, num_workers=0)\n"
      ],
      "metadata": {
        "id": "kVJVM1hJ5UoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    \"\"\"\n",
        "    Computes the accuracy of the predictions.\n",
        "    \"\"\"\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def loss_fn(logits, labels):\n",
        "    \"\"\"\n",
        "    Computes the cross-entropy loss.\n",
        "    \"\"\"\n",
        "    loss_fct = nn.CrossEntropyLoss()\n",
        "    loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "m8KvapIBEMNC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the pre-trained BERT model on the training set\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Set the optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "# Train the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "# Set the number of epochs to train for\n",
        "epochs = 4\n",
        "\n",
        "# Start training loop\n",
        "for epoch in range(epochs):\n",
        "    # Set initial loss value for each epoch\n",
        "    train_loss = 0\n",
        "    # Iterate over the batches in the training set\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Step 1: Load batch data onto GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Clear out any previously calculated gradients\n",
        "        model.zero_grad()\n",
        "        # Step 2: Perform a forward pass\n",
        "        outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        # Step 3: Accumulate the training loss over all of the batches so far\n",
        "        train_loss += loss.item()\n",
        "        # Step 4: Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "        # Step 5: Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # Step 6: Update parameters\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        # Print training progress every 100 steps\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Step [{step}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
        "    # Calculate the average loss over all of the batches\n",
        "    avg_train_loss = train_loss / len(train_dataloader)            \n",
        "    print(\"Epoch {} of {}:\".format(epoch+1, epochs))\n",
        "    print(\"  Training loss: {:.5f}\".format(avg_train_loss))\n",
        "    \n",
        "    # Evaluate the model on the validation set\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "    # Tracking variables \n",
        "    eval_accuracy, eval_loss = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        # Step 1: Load batch data onto GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Step 2: Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Step 3: Perform a forward pass\n",
        "            outputs = model(b_input_ids, \n",
        "                            attention_mask=b_input_mask)\n",
        "            logits = outputs[0]\n",
        "        # Step 4: Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Step 5: Calculate the accuracy and loss for this batch\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        eval_loss += loss_fn(outputs[0], b_labels).item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Calculate the average accuracy and loss over all of the batches\n",
        "    avg_eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    avg_eval_loss = eval_loss / len(validation_dataloader)\n",
        "    print(\"  Validation loss: {:.5f}\".format(avg_eval_loss))\n",
        "    print(\"  Validation Accuracy: {:.5f}\".format(avg_eval_accuracy))\n",
        "\n",
        "    # Save the model checkpoint if the validation loss is the best we've seen so far\n",
        "    if avg_eval_loss < best_eval_loss:\n",
        "        best_eval_loss = avg_eval_loss\n",
        "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "        print(\"  Best model saved\")\n",
        "\n",
        "    # Put the model back in training mode\n",
        "    model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8snOkd239mTd",
        "outputId": "bf5c10a1-0230-4bb8-b412-30ab43615140"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/4], Step [0/40000], Loss: 0.7515\n",
            "Epoch [1/4], Step [100/40000], Loss: 0.2011\n",
            "Epoch [1/4], Step [200/40000], Loss: 0.0670\n",
            "Epoch [1/4], Step [300/40000], Loss: 2.0771\n",
            "Epoch [1/4], Step [400/40000], Loss: 0.0474\n",
            "Epoch [1/4], Step [500/40000], Loss: 0.9978\n",
            "Epoch [1/4], Step [600/40000], Loss: 2.7049\n",
            "Epoch [1/4], Step [700/40000], Loss: 0.0035\n",
            "Epoch [1/4], Step [800/40000], Loss: 0.0107\n",
            "Epoch [1/4], Step [900/40000], Loss: 0.0169\n",
            "Epoch [1/4], Step [1000/40000], Loss: 0.4768\n",
            "Epoch [1/4], Step [1100/40000], Loss: 0.0117\n",
            "Epoch [1/4], Step [1200/40000], Loss: 0.0040\n",
            "Epoch [1/4], Step [1300/40000], Loss: 1.8387\n",
            "Epoch [1/4], Step [1400/40000], Loss: 0.0032\n",
            "Epoch [1/4], Step [1500/40000], Loss: 0.1204\n",
            "Epoch [1/4], Step [1600/40000], Loss: 0.0728\n",
            "Epoch [1/4], Step [1700/40000], Loss: 1.1803\n",
            "Epoch [1/4], Step [1800/40000], Loss: 1.2713\n",
            "Epoch [1/4], Step [1900/40000], Loss: 0.9733\n",
            "Epoch [1/4], Step [2000/40000], Loss: 1.0179\n",
            "Epoch [1/4], Step [2100/40000], Loss: 1.3914\n",
            "Epoch [1/4], Step [2200/40000], Loss: 0.0385\n",
            "Epoch [1/4], Step [2300/40000], Loss: 0.0050\n",
            "Epoch [1/4], Step [2400/40000], Loss: 0.0051\n",
            "Epoch [1/4], Step [2500/40000], Loss: 1.7020\n",
            "Epoch [1/4], Step [2600/40000], Loss: 1.0491\n",
            "Epoch [1/4], Step [2700/40000], Loss: 0.7351\n",
            "Epoch [1/4], Step [2800/40000], Loss: 0.0282\n",
            "Epoch [1/4], Step [2900/40000], Loss: 0.0088\n",
            "Epoch [1/4], Step [3000/40000], Loss: 0.0387\n",
            "Epoch [1/4], Step [3100/40000], Loss: 1.4273\n",
            "Epoch [1/4], Step [3200/40000], Loss: 0.0018\n",
            "Epoch [1/4], Step [3300/40000], Loss: 0.0053\n",
            "Epoch [1/4], Step [3400/40000], Loss: 0.0025\n",
            "Epoch [1/4], Step [3500/40000], Loss: 0.8473\n",
            "Epoch [1/4], Step [3600/40000], Loss: 0.0029\n",
            "Epoch [1/4], Step [3700/40000], Loss: 0.0040\n",
            "Epoch [1/4], Step [3800/40000], Loss: 0.0180\n",
            "Epoch [1/4], Step [3900/40000], Loss: 0.1156\n",
            "Epoch [1/4], Step [4000/40000], Loss: 1.6344\n",
            "Epoch [1/4], Step [4100/40000], Loss: 0.0054\n",
            "Epoch [1/4], Step [4200/40000], Loss: 0.9449\n",
            "Epoch [1/4], Step [4300/40000], Loss: 2.7548\n",
            "Epoch [1/4], Step [4400/40000], Loss: 0.0075\n",
            "Epoch [1/4], Step [4500/40000], Loss: 0.0145\n",
            "Epoch [1/4], Step [4600/40000], Loss: 0.0022\n",
            "Epoch [1/4], Step [4700/40000], Loss: 0.4130\n",
            "Epoch [1/4], Step [4800/40000], Loss: 0.0026\n",
            "Epoch [1/4], Step [4900/40000], Loss: 0.0250\n",
            "Epoch [1/4], Step [5000/40000], Loss: 0.0029\n",
            "Epoch [1/4], Step [5100/40000], Loss: 0.0020\n",
            "Epoch [1/4], Step [5200/40000], Loss: 0.0102\n",
            "Epoch [1/4], Step [5300/40000], Loss: 0.0047\n",
            "Epoch [1/4], Step [5400/40000], Loss: 0.8514\n",
            "Epoch [1/4], Step [5500/40000], Loss: 0.7857\n",
            "Epoch [1/4], Step [5600/40000], Loss: 0.0140\n",
            "Epoch [1/4], Step [5700/40000], Loss: 0.0180\n",
            "Epoch [1/4], Step [5800/40000], Loss: 0.0096\n",
            "Epoch [1/4], Step [5900/40000], Loss: 0.0049\n",
            "Epoch [1/4], Step [6000/40000], Loss: 0.0078\n",
            "Epoch [1/4], Step [6100/40000], Loss: 0.0031\n",
            "Epoch [1/4], Step [6200/40000], Loss: 1.4205\n",
            "Epoch [1/4], Step [6300/40000], Loss: 0.0041\n",
            "Epoch [1/4], Step [6400/40000], Loss: 0.2735\n",
            "Epoch [1/4], Step [6500/40000], Loss: 0.0024\n",
            "Epoch [1/4], Step [6600/40000], Loss: 1.0159\n",
            "Epoch [1/4], Step [6700/40000], Loss: 0.0243\n",
            "Epoch [1/4], Step [6800/40000], Loss: 0.0031\n",
            "Epoch [1/4], Step [6900/40000], Loss: 1.3484\n",
            "Epoch [1/4], Step [7000/40000], Loss: 1.0985\n",
            "Epoch [1/4], Step [7100/40000], Loss: 0.0049\n",
            "Epoch [1/4], Step [7200/40000], Loss: 0.0022\n",
            "Epoch [1/4], Step [7300/40000], Loss: 0.0028\n",
            "Epoch [1/4], Step [7400/40000], Loss: 0.5236\n",
            "Epoch [1/4], Step [7500/40000], Loss: 0.0030\n",
            "Epoch [1/4], Step [7600/40000], Loss: 1.3376\n",
            "Epoch [1/4], Step [7700/40000], Loss: 0.0124\n",
            "Epoch [1/4], Step [7800/40000], Loss: 1.6242\n",
            "Epoch [1/4], Step [7900/40000], Loss: 2.2958\n",
            "Epoch [1/4], Step [8000/40000], Loss: 0.4759\n",
            "Epoch [1/4], Step [8100/40000], Loss: 0.6194\n",
            "Epoch [1/4], Step [8200/40000], Loss: 0.0302\n",
            "Epoch [1/4], Step [8300/40000], Loss: 1.0118\n",
            "Epoch [1/4], Step [8400/40000], Loss: 0.0016\n",
            "Epoch [1/4], Step [8500/40000], Loss: 0.0114\n",
            "Epoch [1/4], Step [8600/40000], Loss: 0.0048\n",
            "Epoch [1/4], Step [8700/40000], Loss: 0.4381\n",
            "Epoch [1/4], Step [8800/40000], Loss: 0.0275\n",
            "Epoch [1/4], Step [8900/40000], Loss: 0.7351\n",
            "Epoch [1/4], Step [9000/40000], Loss: 1.2052\n",
            "Epoch [1/4], Step [9100/40000], Loss: 2.6557\n",
            "Epoch [1/4], Step [9200/40000], Loss: 1.4372\n",
            "Epoch [1/4], Step [9300/40000], Loss: 0.0100\n",
            "Epoch [1/4], Step [9400/40000], Loss: 0.0080\n",
            "Epoch [1/4], Step [9500/40000], Loss: 1.7737\n",
            "Epoch [1/4], Step [9600/40000], Loss: 0.0004\n",
            "Epoch [1/4], Step [9700/40000], Loss: 0.0079\n",
            "Epoch [1/4], Step [9800/40000], Loss: 0.0070\n",
            "Epoch [1/4], Step [9900/40000], Loss: 0.0089\n",
            "Epoch [1/4], Step [10000/40000], Loss: 0.0033\n",
            "Epoch [1/4], Step [10100/40000], Loss: 0.0025\n",
            "Epoch [1/4], Step [10200/40000], Loss: 0.8031\n",
            "Epoch [1/4], Step [10300/40000], Loss: 0.0366\n",
            "Epoch [1/4], Step [10400/40000], Loss: 0.0117\n",
            "Epoch [1/4], Step [10500/40000], Loss: 0.0048\n",
            "Epoch [1/4], Step [10600/40000], Loss: 0.0029\n",
            "Epoch [1/4], Step [10700/40000], Loss: 1.0990\n",
            "Epoch [1/4], Step [10800/40000], Loss: 0.6941\n",
            "Epoch [1/4], Step [10900/40000], Loss: 0.0002\n",
            "Epoch [1/4], Step [11000/40000], Loss: 0.0024\n",
            "Epoch [1/4], Step [11100/40000], Loss: 0.0026\n",
            "Epoch [1/4], Step [11200/40000], Loss: 0.0037\n",
            "Epoch [1/4], Step [11300/40000], Loss: 0.0028\n",
            "Epoch [1/4], Step [11400/40000], Loss: 0.0006\n",
            "Epoch [1/4], Step [11500/40000], Loss: 0.3282\n",
            "Epoch [1/4], Step [11600/40000], Loss: 0.0012\n",
            "Epoch [1/4], Step [11700/40000], Loss: 0.0018\n",
            "Epoch [1/4], Step [11800/40000], Loss: 0.0040\n",
            "Epoch [1/4], Step [11900/40000], Loss: 2.0238\n",
            "Epoch [1/4], Step [12000/40000], Loss: 0.8178\n",
            "Epoch [1/4], Step [12100/40000], Loss: 0.8958\n",
            "Epoch [1/4], Step [12200/40000], Loss: 0.0018\n",
            "Epoch [1/4], Step [12300/40000], Loss: 0.0177\n",
            "Epoch [1/4], Step [12400/40000], Loss: 0.0113\n",
            "Epoch [1/4], Step [12500/40000], Loss: 0.0115\n",
            "Epoch [1/4], Step [12600/40000], Loss: 0.0017\n",
            "Epoch [1/4], Step [12700/40000], Loss: 1.3893\n",
            "Epoch [1/4], Step [12800/40000], Loss: 0.0011\n",
            "Epoch [1/4], Step [12900/40000], Loss: 0.7970\n",
            "Epoch [1/4], Step [13000/40000], Loss: 0.0018\n",
            "Epoch [1/4], Step [13100/40000], Loss: 0.0057\n",
            "Epoch [1/4], Step [13200/40000], Loss: 0.0128\n",
            "Epoch [1/4], Step [13300/40000], Loss: 1.4390\n",
            "Epoch [1/4], Step [13400/40000], Loss: 0.0062\n",
            "Epoch [1/4], Step [13500/40000], Loss: 0.0032\n",
            "Epoch [1/4], Step [13600/40000], Loss: 0.0025\n",
            "Epoch [1/4], Step [13700/40000], Loss: 1.2142\n",
            "Epoch [1/4], Step [13800/40000], Loss: 0.0012\n",
            "Epoch [1/4], Step [13900/40000], Loss: 0.0012\n",
            "Epoch [1/4], Step [14000/40000], Loss: 0.0117\n",
            "Epoch [1/4], Step [14100/40000], Loss: 1.3650\n",
            "Epoch [1/4], Step [14200/40000], Loss: 0.9975\n",
            "Epoch [1/4], Step [14300/40000], Loss: 0.2431\n",
            "Epoch [1/4], Step [14400/40000], Loss: 0.0014\n",
            "Epoch [1/4], Step [14500/40000], Loss: 0.8666\n",
            "Epoch [1/4], Step [14600/40000], Loss: 0.0035\n",
            "Epoch [1/4], Step [14700/40000], Loss: 0.0063\n",
            "Epoch [1/4], Step [14800/40000], Loss: 0.5787\n",
            "Epoch [1/4], Step [14900/40000], Loss: 0.0726\n",
            "Epoch [1/4], Step [15000/40000], Loss: 0.0024\n",
            "Epoch [1/4], Step [15100/40000], Loss: 0.0014\n",
            "Epoch [1/4], Step [15200/40000], Loss: 0.4691\n",
            "Epoch [1/4], Step [15300/40000], Loss: 0.0005\n",
            "Epoch [1/4], Step [15400/40000], Loss: 0.0031\n",
            "Epoch [1/4], Step [15500/40000], Loss: 0.0007\n",
            "Epoch [1/4], Step [15600/40000], Loss: 1.4167\n",
            "Epoch [1/4], Step [15700/40000], Loss: 0.0286\n",
            "Epoch [1/4], Step [15800/40000], Loss: 0.0015\n",
            "Epoch [1/4], Step [15900/40000], Loss: 1.5938\n",
            "Epoch [1/4], Step [16000/40000], Loss: 1.0583\n",
            "Epoch [1/4], Step [16100/40000], Loss: 0.0027\n",
            "Epoch [1/4], Step [16200/40000], Loss: 0.6031\n",
            "Epoch [1/4], Step [16300/40000], Loss: 2.7024\n",
            "Epoch [1/4], Step [16400/40000], Loss: 0.7948\n",
            "Epoch [1/4], Step [16500/40000], Loss: 0.0009\n",
            "Epoch [1/4], Step [16600/40000], Loss: 0.0036\n",
            "Epoch [1/4], Step [16700/40000], Loss: 0.0007\n",
            "Epoch [1/4], Step [16800/40000], Loss: 0.0060\n",
            "Epoch [1/4], Step [16900/40000], Loss: 0.0070\n",
            "Epoch [1/4], Step [17000/40000], Loss: 0.0011\n",
            "Epoch [1/4], Step [17100/40000], Loss: 0.0061\n",
            "Epoch [1/4], Step [17200/40000], Loss: 0.0031\n",
            "Epoch [1/4], Step [17300/40000], Loss: 1.4618\n",
            "Epoch [1/4], Step [17400/40000], Loss: 1.5969\n",
            "Epoch [1/4], Step [17500/40000], Loss: 0.0038\n",
            "Epoch [1/4], Step [17600/40000], Loss: 1.5014\n",
            "Epoch [1/4], Step [17700/40000], Loss: 0.0034\n",
            "Epoch [1/4], Step [17800/40000], Loss: 0.0102\n",
            "Epoch [1/4], Step [17900/40000], Loss: 0.0065\n",
            "Epoch [1/4], Step [18000/40000], Loss: 0.0016\n",
            "Epoch [1/4], Step [18100/40000], Loss: 0.0180\n",
            "Epoch [1/4], Step [18200/40000], Loss: 0.4383\n",
            "Epoch [1/4], Step [18300/40000], Loss: 0.0008\n",
            "Epoch [1/4], Step [18400/40000], Loss: 0.0565\n",
            "Epoch [1/4], Step [18500/40000], Loss: 0.0010\n",
            "Epoch [1/4], Step [18600/40000], Loss: 0.0064\n",
            "Epoch [1/4], Step [18700/40000], Loss: 0.0031\n",
            "Epoch [1/4], Step [18800/40000], Loss: 0.0007\n",
            "Epoch [1/4], Step [18900/40000], Loss: 1.7104\n",
            "Epoch [1/4], Step [19000/40000], Loss: 0.0018\n",
            "Epoch [1/4], Step [19100/40000], Loss: 0.0038\n",
            "Epoch [1/4], Step [19200/40000], Loss: 0.7870\n",
            "Epoch [1/4], Step [19300/40000], Loss: 0.0038\n",
            "Epoch [1/4], Step [19400/40000], Loss: 1.7775\n",
            "Epoch [1/4], Step [19500/40000], Loss: 0.0018\n",
            "Epoch [1/4], Step [19600/40000], Loss: 0.0019\n",
            "Epoch [1/4], Step [19700/40000], Loss: 0.0026\n",
            "Epoch [1/4], Step [19800/40000], Loss: 0.0008\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-01afd64d2ef9>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Step 1: Load batch data onto GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Unpack the inputs from our dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-01afd64d2ef9>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Step 1: Load batch data onto GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Unpack the inputs from our dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_bert_model(model, dataloader):\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    \n",
        "    # Tracking variables \n",
        "    eval_accuracy, eval_loss = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    y_true, y_pred = [], []\n",
        "    \n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dataloader:\n",
        "        # Step 1: Load batch data onto GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Step 2: Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Step 3: Perform a forward pass\n",
        "            outputs = model(b_input_ids, \n",
        "                            attention_mask=b_input_mask)\n",
        "            logits = outputs[0]\n",
        "        # Step 4: Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Step 5: Calculate the accuracy and loss for this batch\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        eval_loss += loss_fn(outputs[0], b_labels).item()\n",
        "        nb_eval_steps += 1\n",
        "        \n",
        "        y_true.extend(label_ids)\n",
        "        y_pred.extend(np.argmax(logits, axis=1))\n",
        "\n",
        "    # Calculate the average accuracy and loss over all of the batches\n",
        "    avg_eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    avg_eval_loss = eval_loss / len(dataloader)\n",
        "    \n",
        "    # Calculate classification metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    clf_report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    return {\n",
        "        'Accuracy': acc,\n",
        "        'F1 Score (Negative)': clf_report['0']['f1-score'],\n",
        "        'F1 Score (Positive)': clf_report['1']['f1-score'],\n",
        "        'Precision (Negative)': clf_report['0']['precision'],\n",
        "        'Precision (Positive)': clf_report['1']['precision'],\n",
        "        'Recall (Negative)': clf_report['0']['recall'],\n",
        "        'Recall (Positive)': clf_report['1']['recall'],\n",
        "        'Confusion Matrix': cm\n",
        "    }\n",
        "\n",
        "#model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "evaluate_bert_model(model, validation_dataloader)"
      ],
      "metadata": {
        "id": "_v0x7nKeHe05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f01c225-ccbf-4022-db5a-c298b5681a83"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.920125,\n",
              " 'F1 Score (Negative)': 0.9195922989807475,\n",
              " 'F1 Score (Positive)': 0.9206506891841548,\n",
              " 'Precision (Negative)': 0.926094890510949,\n",
              " 'Precision (Positive)': 0.9143153117600631,\n",
              " 'Recall (Negative)': 0.9131803868645973,\n",
              " 'Recall (Positive)': 0.9270744760666233,\n",
              " 'Confusion Matrix': array([[18270,  1737],\n",
              "        [ 1458, 18535]])}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to make predictions on new text\n",
        "def predict(text):\n",
        "    # Load the saved model state\n",
        "    model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "    # Tokenize the text and convert to input features\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    # Move the inputs to the device the model is on\n",
        "    inputs.to(device)\n",
        "    # Make the prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "    logits = outputs[0]\n",
        "    # Get the predicted class\n",
        "    predicted_class = torch.argmax(logits).item()\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "gO4klb3PAQK8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TdEidj1CFcoP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}